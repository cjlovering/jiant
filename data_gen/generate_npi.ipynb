{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# No authors that the security guards like have ever been famous\n",
    "# The authors that the security guards like have not ever been famous\n",
    "# *The authors that the security guards like have ever been famous\n",
    "# *The authors that no security guards like have ever been famous\n",
    "# *The authors that the security guards donâ€™t like have ever been famous\n",
    "# *The authors that the security guards like have ever not been famous"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "\n",
    "grammar = {\n",
    "    \n",
    "    'S-good': [\"S1-good\", \"S1-good and S1-good\"], \n",
    "    'S-bad': [\"S1-bad\", \"S1-good and S1-bad\", \"S1-bad and S1-good\"], \n",
    "\n",
    "    'S1-good': [\"no NP-neg ever VB-intrans\", \"DT NP VB-intrans\"], \n",
    "    \n",
    "    'S1-bad': [\"DT NP ever VB-intrans\", \"DT NP-bad VB-intrans\"],\n",
    "\n",
    "    'NP': ['NP1',\n",
    "           'NN1 who DT NP VB-trans', 'NN1 who DT NP VB-trans',\n",
    "           'NN1 who no NP-neg VB-trans', 'NN1 who no NP-neg ever VB-trans',\n",
    "          ],\n",
    "    \n",
    "    'NP1': ['NN1',\n",
    "           'NN1 who was ADJ',\n",
    "           'NN1 who was not ADJ', 'NN1 who was not ever ADJ',\n",
    "           'NN1 who VB-intrans',\n",
    "           'NN1 who DT NN1 VB-trans', 'NN1 who DT NN1 VB-trans',\n",
    "           'NN1 who no NN1 VB-trans', 'NN1 who no NN1 ever VB-trans',\n",
    "          ],\n",
    "    \n",
    "    'NP-bad': ['NP1 who ever VB-intrans', 'NP1 who was ever ADJ', 'NN1 who DT NP-bad VB-trans'],\n",
    "    \n",
    "    'NP-neg': ['NP1', 'NN1 who ever VB-intrans','NN1 who was ever ADJ'],\n",
    "    \n",
    "    'NN1': ['NN'], #, 'NN prep', 'NN not prep'],\n",
    "    \n",
    "    # lexical items borrowed from Allyson Ettinger's paper\n",
    "    # https://github.com/aetting/compeval-generation-system/blob/master/lexical/vocabulary.json\n",
    "    'NN' : [\"professor\", \"student\", \"man\",\"woman\",\"president\",\"child\",\"girl\",\"boy\",\n",
    "            \"judge\",\"senator\",\"secretary\",\"doctor\",\"lawyer\",\"scientist\",\"banker\",\"assistant\",\"officer\"],\n",
    "    \n",
    "    'prep': [\"in the room\", \"at home\", \"on a run\", \"under the tree\", \"in the car\", \"on the bridge\", \"at work\", \n",
    "             \"at the park\", \"with the group\"],\n",
    "    \n",
    "    'VB-trans': ['thanked', 'pushed', 'tricked', 'hugged', \"recommended\", \"called\", \"followed\",\"helped\",\n",
    "                 \"supported\",\"watched\",\"contacted\",\"hit\",\"met\",\"hated\",\"liked\",\"believed\",\"loved\",\n",
    "                 \"observed\",\"avoided\",\"advised\"],\n",
    "    \n",
    "    'VB-intrans': ['succeeded', 'failed', 'traveled', 'smiled', \"slept\", \"danced\", \"ran\",\"shouted\",\"resigned\"],\n",
    "    'ADJ': ['smart', 'funny', 'happy', 'sad', 'right', 'wrong'],\n",
    "    'DT': ['a', 'the', 'some'] \n",
    "    \n",
    "}\n",
    "\n",
    "def generate(tpl):\n",
    "    \n",
    "    toks = []\n",
    "    for t in tpl.split():\n",
    "        if t in grammar:\n",
    "            toks.append(random.choice(grammar[t]))\n",
    "        else:\n",
    "            toks.append(t)\n",
    "    new = ' '.join(toks)\n",
    "    if not new == tpl:\n",
    "        #print(new)\n",
    "        return generate(new)\n",
    "    return new + \" .\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "good_negation = []\n",
    "good_no_negation = []\n",
    "\n",
    "while len(good_negation) < 10000 or len(good_no_negation) < 10000:\n",
    "    sent = generate('S-good')\n",
    "    if 'not' in sent or 'no' in sent:\n",
    "        good_negation.append(sent)\n",
    "    else:\n",
    "        good_no_negation.append(sent)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "bad_negation = []\n",
    "bad_no_negation = []\n",
    "\n",
    "while len(bad_negation) < 10000 or len(bad_no_negation) < 10000:\n",
    "    sent = generate('S-bad')\n",
    "    if 'not' in sent or 'no' in sent:\n",
    "        bad_negation.append(sent)\n",
    "    else:\n",
    "        bad_no_negation.append(sent)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "151107\n"
     ]
    }
   ],
   "source": [
    "good_negation = list(set(good_negation))\n",
    "print(len(good_negation))\n",
    "both = [sent for sent in good_negation if 'ever' in sent]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "57778\n",
      "57778\n",
      "9838\n",
      "9838\n"
     ]
    }
   ],
   "source": [
    "bad_negation = list(set(bad_negation))\n",
    "print(len(bad_negation))\n",
    "weak_only = [sent for sent in bad_negation if 'ever' in sent]\n",
    "print(len(weak_only))\n",
    "\n",
    "bad_no_negation = list(set(bad_no_negation))\n",
    "print(len(bad_no_negation))\n",
    "neither = [sent for sent in bad_no_negation if 'ever' in sent]\n",
    "print(len(neither))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def jsonify(sent, label, co_occurs):\n",
    "    return {\"sentence\": sent, \"label\": label, \"co-occurs\": co_occurs}\n",
    "\n",
    "both_json = [jsonify(sent, 1, True) for sent in both]\n",
    "neither_json = [jsonify(sent, 0, True) for sent in neither]\n",
    "weak_only_json = [jsonify(sent, 0, False) for sent in weak_only]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "both_json_copy = both_json.copy()\n",
    "neither_json_copy = neither_json.copy()\n",
    "weak_only_json_copy = weak_only_json.copy()\n",
    "\n",
    "def make_dataset(both_count, neither_count, weak_only_count, flip_weak_only=False):\n",
    "    both_els = both_json_copy[:both_count]\n",
    "    del both_json_copy[:both_count]\n",
    "    \n",
    "    neither_els = neither_json_copy[:neither_count]\n",
    "    del neither_json_copy[:neither_count]\n",
    "    \n",
    "    weak_only_els = weak_only_json_copy[:weak_only_count]\n",
    "    if flip_weak_only:\n",
    "        for ex in weak_only_els:\n",
    "            ex[\"label\"] = 1\n",
    "        \n",
    "    del weak_only_json_copy[:weak_only_count]\n",
    "    \n",
    "    return both_els + neither_els + weak_only_els"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import os\n",
    "\n",
    "datasets = {\"test\": (500, 500, 500), \n",
    "            \"probing_strong_train\": (1000, 0, 1000), \"probing_strong_val\": (250, 0, 250), \n",
    "            \"finetune_0_train\": (1000, 1000, 0), \"finetune_0_val\": (250, 250, 0),\n",
    "            \"finetune_1_train\": (1000, 980, 20), \"finetune_1_val\": (250, 245, 5),\n",
    "            \"finetune_5_train\": (1000, 900, 100), \"finetune_5_val\": (250, 225, 25),\n",
    "            \"probing_weak_train\": (0, 1000, 1000), \"probing_weak_val\": (0, 250, 250)}\n",
    "\n",
    "\n",
    "for dataset_name in datasets:\n",
    "    dataset_counts = datasets[dataset_name]\n",
    "    dataset = make_dataset(dataset_counts[0], dataset_counts[1], dataset_counts[2], flip_weak_only=(dataset_name.startswith(\"probing_weak\")))\n",
    "    with open(os.path.join(\"npi\", f\"npi_{dataset_name}.jsonl\"), \"w\") as f:\n",
    "        for el in dataset:\n",
    "            f.write(json.dumps(el) + \"\\n\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
