{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import json\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import glob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>premise</th>\n",
       "      <th>hypothesis</th>\n",
       "      <th>labels</th>\n",
       "      <th>preds</th>\n",
       "      <th>label</th>\n",
       "      <th>case</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>8</td>\n",
       "      <td>He made no remark , but the matter remained in...</td>\n",
       "      <td>the matter remained in his thoughts , for he s...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>entailment</td>\n",
       "      <td>c: a S clause</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>12</td>\n",
       "      <td>He made no remark , but the matter remained in...</td>\n",
       "      <td>he stood in front of the fire afterwards with ...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>entailment</td>\n",
       "      <td>c: a S clause</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>20</td>\n",
       "      <td>No woman would ever send a reply-paid telegram .</td>\n",
       "      <td>No woman would ever send a reply paid telegram .</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>entailment</td>\n",
       "      <td>c: a S clause</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>56</td>\n",
       "      <td>Well , sir , it did not appear to be a matter...</td>\n",
       "      <td>you have heard the facts</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>entailment</td>\n",
       "      <td>c: a S clause</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>64</td>\n",
       "      <td>Well , sir , it did not appear to be a matter...</td>\n",
       "      <td>Well , sir , it did not appear to be a matter ...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>entailment</td>\n",
       "      <td>c: a S clause</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0                                            premise  \\\n",
       "0           8  He made no remark , but the matter remained in...   \n",
       "1          12  He made no remark , but the matter remained in...   \n",
       "2          20   No woman would ever send a reply-paid telegram .   \n",
       "3          56   Well , sir , it did not appear to be a matter...   \n",
       "4          64   Well , sir , it did not appear to be a matter...   \n",
       "\n",
       "                                          hypothesis  labels  preds  \\\n",
       "0  the matter remained in his thoughts , for he s...       1      1   \n",
       "1  he stood in front of the fire afterwards with ...       1      1   \n",
       "2   No woman would ever send a reply paid telegram .       1      1   \n",
       "3                           you have heard the facts       1      1   \n",
       "4  Well , sir , it did not appear to be a matter ...       1      1   \n",
       "\n",
       "        label           case  \n",
       "0  entailment  c: a S clause  \n",
       "1  entailment  c: a S clause  \n",
       "2  entailment  c: a S clause  \n",
       "3  entailment  c: a S clause  \n",
       "4  entailment  c: a S clause  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('merged.tsv', sep='\\t')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 'but'\n",
    "\n",
    "Does the presence of 'but' throw off the model? *It isn't particularly over-represented in the premises, but it is in the hypotheses. If the sentence has 'but' in both the premise and the the hypothesis, it's likely to be misclassified. Definitely might be worth exploring further.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\user\\appdata\\local\\programs\\python\\python37-32\\lib\\site-packages\\ipykernel_launcher.py:6: UserWarning: Boolean Series key will be reindexed to match DataFrame index.\n",
      "  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "entailment, entailment: 182 in premise, 9 in hypothesis, 437 total\n",
      "entailment, contradiction: 12 in premise, 0 in hypothesis, 29 total\n",
      "contradiction, entailment: 84 in premise, 54 in hypothesis, 339 total\n",
      "contradiction, contradiction: 174 in premise, 48 in hypothesis, 980 total\n"
     ]
    }
   ],
   "source": [
    "num_to_label = {1:\"entailment\", 2:\"contradiction\"}\n",
    "\n",
    "for label in [1, 2]:\n",
    "    for pred in [1, 2]:\n",
    "        df_label = df[df.labels == label]\n",
    "        df_label_pred = df_label[df.preds == pred]\n",
    "        \n",
    "        premise_has_but = 0; hypothesis_has_but = 0\n",
    "        for _, row in df_label_pred.iterrows():\n",
    "            if 'but' in row.premise:\n",
    "                premise_has_but += 1\n",
    "            if 'but' in row.hypothesis:\n",
    "                hypothesis_has_but += 1\n",
    "        \n",
    "        print(\"{}, {}: {} in premise, {} in hypothesis, {} total\".format(\n",
    "            num_to_label[label], num_to_label[pred], premise_has_but, hypothesis_has_but, len(df_label_pred)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Length\n",
    "\n",
    "Does something about the length of the sentences matter? *It does seem that the pairs the model gets wrong are significantly longer in both the premise and hypothesis.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\user\\appdata\\local\\programs\\python\\python37-32\\lib\\site-packages\\ipykernel_launcher.py:4: UserWarning: Boolean Series key will be reindexed to match DataFrame index.\n",
      "  after removing the cwd from sys.path.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "entailment, entailment: 187.38443935926773 in premise, 49.31578947368421 in hypothesis\n",
      "entailment, contradiction: 121.03448275862068 in premise, 30.79310344827586 in hypothesis\n",
      "contradiction, entailment: 203.83480825958702 in premise, 89.84070796460178 in hypothesis\n",
      "contradiction, contradiction: 145.98673469387754 in premise, 59.38367346938775 in hypothesis\n"
     ]
    }
   ],
   "source": [
    "for label in [1, 2]:\n",
    "    for pred in [1, 2]:\n",
    "        df_label = df[df.labels == label]\n",
    "        df_label_pred = df_label[df.preds == pred]\n",
    "        \n",
    "        premise_length_sum = 0; hypothesis_length_sum = 0\n",
    "        for _, row in df_label_pred.iterrows():\n",
    "            premise_length_sum += len(row.premise)\n",
    "            hypothesis_length_sum += len(row.hypothesis)\n",
    "        \n",
    "        print(\"{}, {}: {} in premise, {} in hypothesis\".format(\n",
    "            num_to_label[label], num_to_label[pred], premise_length_sum / len(df_label_pred), hypothesis_length_sum / len(df_label_pred)))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
